HW2
================
Chen Mo
9/28/2020

load library

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

define a path to the dataset

``` r
path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

\#Problem 1

Read the Mr. Trashwheel dataset

``` r
 trashwheel_df = 
        read_xlsx(
                path = path_to_data,
                sheet = "Mr. Trash Wheel",
                range = cell_cols("A:N")) %>%
        janitor::clean_names() %>%
        drop_na(dumpster) %>%
        mutate(
                sports_balls = round(sports_balls),
                sports_balls = as.integer(sports_balls)
        )
```

Read the 2017 precipitation data.

``` r
precip_2017 =
        read_excel(
                path = path_to_data,
                sheet = "2017 Precipitation",
                skip = 1
        ) %>% 
        janitor::clean_names() %>% 
        drop_na(month) %>% 
        mutate(year = 2017) %>%
        relocate(year)
```

Read the 2018 precipitation data.

``` r
precip_2018 =
        read_excel(
                path = path_to_data,
                sheet = "2018 Precipitation",
                skip = 1
        ) %>% 
        janitor::clean_names() %>% 
        drop_na(month) %>% 
        mutate(year = 2018) %>%
        relocate(year)
```

Combine annual precipitation data.

``` r
month_df =
        tibble(
                month= 1:12,
                month_name = month.name
        )
precip_df =
        bind_rows(precip_2017, precip_2018)

precip_df =
        left_join(precip_df, month_df, by = "month") %>% 
        select(-month)
```

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data.The
dataset contains information on year, total precipitation, and month
names. There are a total of 24 rows in the precipitation dataset. In two
datasets:

  - The median number of sports balls found in a dumpster in 2017 was 8
  - The total precipitation in 2018 was 70.33 inches.

\#Problem 2

read the NYC transit data.

``` r
nyc_transit_df = 
        read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
        ) %>%
        janitor::clean_names() %>%
        select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada) %>%
        mutate(entry = recode(entry, "YES" = T, "NO" = F))  
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

This dataset contains information about entrances and exits for subway
stations in NYC. The dataset contains information on station name, line
name, station location(latitude/longitude), routes served for each
station, and some information about entrance, vending and ADA
compliance.

For my data cleaning steps, first, I use read\_csv function to read the
dataset from the original csv file. Then, I use clean\_names function to
clean all the names in this dataset. Thirdly, I use select to retain all
the columns which I want to be included in the dataset. Finally, I use
mutate function to convert the entry variable from a character variable
to a logical variable.

The dataset contains 1868 rows and 19 columns.

The dataset is not tidy enough. For example, the values for line
variable contain “4 Avenue”, “6 Avenue”, and “42nd St Shuttle”. These
three values are not in the same format. And, there are so many
routes(from “route1” to “route2”), which is so complex.

There are 465 distinct stations.  
There are 468 stations with ADA compliant.  
0.0393611 of station entrances/exits without vending allow entrance.

Reformat data:

``` r
nyc_transit_df = 
        nyc_transit_df %>% 
        mutate(
                route8 = as.character(route8),
                route9 = as.character(route9),
                route10 = as.character(route10),
                route11 = as.character(route11)
        )
nyc_transit_tidy = 
        nyc_transit_df %>% 
        pivot_longer(
                route1:route11,
                values_to = "route_name",
                names_to = "route_number"
) %>%
        separate(route_number, into = c("route", "route_number"), sep = 5) %>% 
        select(-route)
```

There are 60 distinct stations serve the A train. Of the 60 stations
that serve the A train, 17 are ADA compliant.
