---
title: "HW2"
author: "Chen Mo"
date: "9/28/2020"
output: github_document
---

Load library:

```{r}
library(tidyverse)
library(readxl)
```

Define a path to the dataset:

```{r}
path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

#Problem 1

Read the Mr. Trashwheel dataset

```{r}
 trashwheel_df = 
        read_xlsx(
                path = path_to_data,
                sheet = "Mr. Trash Wheel",
                range = cell_cols("A:N")) %>%
        janitor::clean_names() %>%
        drop_na(dumpster) %>%
        mutate(
                sports_balls = round(sports_balls),
                sports_balls = as.integer(sports_balls)
        )
```

Read the 2017 precipitation data.

```{r}
precip_2017 =
        read_excel(
                path = path_to_data,
                sheet = "2017 Precipitation",
                skip = 1
        ) %>% 
        janitor::clean_names() %>% 
        drop_na(month) %>% 
        mutate(year = 2017) %>%
        relocate(year)
```

Read the 2018 precipitation data.

```{r}
precip_2018 =
        read_excel(
                path = path_to_data,
                sheet = "2018 Precipitation",
                skip = 1
        ) %>% 
        janitor::clean_names() %>% 
        drop_na(month) %>% 
        mutate(year = 2018) %>%
        relocate(year)
```

Combine annual precipitation data.

```{r}
month_df =
        tibble(
                month= 1:12,
                month_name = month.name
        )
precip_df =
        bind_rows(precip_2017, precip_2018)

precip_df =
        left_join(precip_df, month_df, by = "month") %>% 
        select(-month)
```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data.The dataset contains information on year, total precipitation, and month names. There are a total of `r nrow(precip_df)` rows in the precipitation dataset. In two datasets:

* The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
* The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.

#Problem 2

Read the NYC transit data.

```{r}
nyc_transit_df = 
        read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
        janitor::clean_names() %>%
        select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada) %>%
        mutate(entry = recode(entry, "YES" = T, "NO" = F))  
```

This dataset contains information about entrances and exits for subway stations in NYC. The dataset contains information on station name, line name, station location(latitude/longitude), routes served for each station, and some information about entrance, vending and ADA compliance. 


For my data cleaning steps, first, I use read_csv function to read the dataset from the original csv file. Then, I use clean_names function to clean all the names in this dataset. Thirdly, I use select to retain all the columns which I want to be included in the dataset. Finally, I use mutate function to convert the entry variable from a character variable to a logical variable.  

The dataset contains `r nrow(nyc_transit_df)` rows and `r ncol(nyc_transit_df)` columns. 

The dataset is not tidy enough. For example, the values for line variable contain "4 Avenue", "6 Avenue", and "42nd St Shuttle". These three values are not in the same format. And, there are so many routes(from "route1" to "route2"), which is so complex. Moreover, some lines have same values for each variable, which is meaningless.  

There are `r nrow(distinct(nyc_transit_df, line, station_name))` distinct stations.  
There are `r filter(nyc_transit_df, ada =="TRUE") %>%  distinct(line, station_name) %>% nrow()` stations with ADA compliant.  
`r  nrow(filter(nyc_transit_df, vending == "NO", entry == "TRUE"))/nrow(filter(nyc_transit_df, vending == "NO"))` of station entrances/exits without vending allow entrance.

Reformat data:

```{r}
nyc_transit_df = 
        nyc_transit_df %>% 
        mutate(
                route8 = as.character(route8),
                route9 = as.character(route9),
                route10 = as.character(route10),
                route11 = as.character(route11)
        )
nyc_transit_tidy = 
        nyc_transit_df %>% 
        pivot_longer(
                route1:route11,
                names_to = "route_name",
                values_to = "route_number"
) %>%
        separate(route_name, into = c("route", "route_name"), sep = 5) %>% 
        select(-route)
```

There are `r filter(nyc_transit_tidy, route_number == "A") %>% distinct(line, station_name) %>%  nrow()` distinct stations serve the A train. Of the `r filter(nyc_transit_tidy, route_number == "A") %>% distinct(line, station_name) %>% nrow()` stations that serve the A train, `r filter(nyc_transit_tidy, route_number == "A", ada == "TRUE") %>%  distinct(line, station_name) %>%  nrow()` are ADA compliant.

#Problem 3

Load and clean data in pols-month.csv:

```{r}
month_df = tibble(
                  month = 1:12,
                  month_name = month.name)
pols_month_df = 
          read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
          janitor::clean_names() %>%
          separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
          mutate(
                  month = as.integer(month)) %>% 
         left_join(month_df, by = "month") %>% 
         select(-month) %>% 
         relocate(year, month_name) %>% 
         rename("month" = "month_name") %>% 
         mutate(
                 president = recode(prez_gop, "1" = "gop", "0" = "dem")
         ) %>% 
        select(-prez_dem) %>%
        select(-prez_gop) %>% 
        select(-day)
```

Load and clean data in snp.csv:

```{r}
snp_df = 
        read_csv("./data/fivethirtyeight_datasets/snp.csv") %>%
        janitor::clean_names() %>%
        separate(date, into = c("month", "day", "year"), sep = "/") %>% 
        mutate(
                month = as.integer(month)) %>%
        left_join(month_df, by = "month") %>% 
         select(-month, -day) %>% 
         relocate(year, month_name) %>% 
         rename("month" = "month_name") 
```

Load and clean data in unemployment.csv:

```{r}
month_name_df = tibble(
        month = str_to_lower(month.abb),
        month_name = month.name
)
unemploy_df = 
        read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
        janitor::clean_names() %>%
        pivot_longer(
                jan:dec,
                values_to = "unemployment_rate",
                names_to = "month"
        ) %>%
        left_join(month_name_df, by = "month") %>% 
        select(-month) %>% 
        rename(month = month_name) %>% 
        relocate(year, month)
```

Then,join all the datasets:

```{r}
joint_df = merge(pols_month_df, snp_df) %>% 
        merge(unemploy_df)
```
There are four datasets in total. The first dataset is the pols_month_df dataset, which contains the information on year, month, type of president, number of republican governors, number of republican senators, number of republican representatives, number of democratic governors, number of democratic senators, number of democratic representatives on the associated date. It have `r nrow(pols_month_df)` rows and `r ncol(pols_month_df)` columns in total. The range of year is ranged from `r min(pull(pols_month_df, year))` to `r max(pull(pols_month_df, year))`. The key variable is the president variable which indicates the information about whether the president was republican or democratic on the associated date.  

The second dataset is the snp_df dataset. It contains the information on year, month, and the closing values of the S&P stock index on the associated date. It have `r nrow(snp_df)` rows and `r ncol(snp_df)` columns in total. The range of year is ranged from `r min(pull(snp_df, year))` to `r max(pull(snp_df, year))`. The key variable is the close variable which shows the closing values of the S&P stock index on the associated date.  

The third dataset is the unemploy_df dataset. It contains the information on year, month, and percentage of unemployment on the associated date. It have `r nrow(unemploy_df)` rows and `r ncol(unemploy_df)` columns in total. The range of year is ranged from `r min(pull(unemploy_df, year))` to `r max(pull(unemploy_df, year))`. The key variable is the unemployment_rate variable which contains the information on the percentage of unemployment on the associated date. 

The last dataset is the joint_df dataset, which contains the information on year, month, type of president, number of republican governors, number of republican senators, number of republican representatives, number of democratic governors, number of democratic senators, number of democratic representatives, the closing values of the S&P stock index, and percentage of unemployment on the associated date. It have `r nrow(joint_df)` rows and `r ncol(joint_df)` columns in total. The range of year is ranged from `r min(pull(joint_df, year))` to `r max(pull(joint_df, year))`.

For the steps of data wrangling, I import all the datasets at first, then, I clean all the datasets by using clean_names fuction in janitor library and by using separate funtion to break up the variable mon into integer variables year, month, and day.Finally, I merge all the dataset into one dataset using merge function joint by mon variable and year variable.




